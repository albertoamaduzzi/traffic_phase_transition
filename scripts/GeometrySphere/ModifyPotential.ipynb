{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother_path: /home/alberto/LPSim/traffic_phase_transition/scripts\n",
      "\u001b[33mInitialize Grid: 0.02\u001b[0m\n",
      "\u001b[33mALREADY COMPUTED\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import unary_union\n",
    "import socket\n",
    "current_dir = os.path.join(os.getcwd()) \n",
    "mother_path = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "print('mother_path:', mother_path)\n",
    "sys.path.append(os.path.join(mother_path, 'PreProcessing'))\n",
    "sys.path.append(os.path.join(mother_path))\n",
    "from FittingProcedures import *\n",
    "from plot import *\n",
    "from Potential import *\n",
    "from Grid import *\n",
    "from PreprocessingObj import *\n",
    "from ODfromfma import *\n",
    "import time\n",
    "\n",
    "## BASIC PARAMS\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "})\n",
    "\n",
    "if socket.gethostname()=='artemis.ist.berkeley.edu':\n",
    "    TRAFFIC_DIR = '/home/alberto/LPSim/traffic_phase_transition'\n",
    "else:\n",
    "    TRAFFIC_DIR = os.getenv('TRAFFIC_DIR')\n",
    "name = 'BOS'\n",
    "grid_size = 0.02\n",
    "hexagon_resolution = 8\n",
    "dir_grid = os.path.join(TRAFFIC_DIR,'data','carto',name,'grid',str(grid_size))\n",
    "\n",
    "## BASIC NEEDED OBJECTS\n",
    "SFO_obj = GeometricalSettingsSpatialPartition(name,TRAFFIC_DIR)\n",
    "bbox = SFO_obj.bounding_box\n",
    "minx, miny, maxx, maxy = bbox\n",
    "dir_geometries = os.path.join(TRAFFIC_DIR,'data','carto','{0}'.format(name))\n",
    "grid = GetGrid(grid_size,SFO_obj.bounding_box,'EPSG:4326',dir_geometries)\n",
    "df_distance,FoundDistMat = GetDirectionMatrix(dir_geometries,grid_size)\n",
    "Tij = GetODGrid(dir_geometries,str(grid_size))\n",
    "lattice = nx.read_graphml(os.path.join(dir_grid,\"centroid_lattice.graphml\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIFY POPULATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ComputeVectorFieldModified(Tij,df_distance):\n",
    "    Tij['vector_flux'] = df_distance['dir_vector'].apply(lambda x: parse_dir_vector(x) ) * Tij['number_people']\n",
    "\n",
    "    # Create VectorField DataFrame\n",
    "    VectorField = pd.DataFrame(index=Tij['(i,j)D'].unique(), columns=['(i,j)', 'Ti', 'Tj'])\n",
    "    Tj_values = Tij.groupby('(i,j)D')['vector_flux'].sum()\n",
    "    VectorField['Tj'] = Tj_values\n",
    "\n",
    "    # Calculate 'Ti' values\n",
    "    Ti_values = Tij.groupby('(i,j)O')['vector_flux'].sum()\n",
    "    VectorField['Ti'] = Ti_values\n",
    "    VectorField['index'] = VectorField.index\n",
    "    VectorField['(i,j)'] = VectorField['index']\n",
    "    VectorField['index'] = VectorField.index\n",
    "    VectorField.reset_index(inplace=True)\n",
    "    return VectorField\n",
    "\n",
    "def ReassignPopulationRandomly(population, m0, m1, N):\n",
    "    '''\n",
    "        This function reassign population according to ModifyPop principles\n",
    "    '''\n",
    "    indices = np.where(population > 0)[0]  # Step 1\n",
    "\n",
    "    for _ in range(N):\n",
    "        index = np.random.choice(indices)  # Step 2\n",
    "        rand_value = np.random.exponential(m0)  # Step 3\n",
    "        exp_value = np.exp(-population[index] / m1)  # Exponential value of vector[index] / b\n",
    "        if rand_value > exp_value:  # Step 4\n",
    "            population[index] = 0\n",
    "            index1 = np.random.choice(indices)\n",
    "            population[index1] += rand_value  # Step 5\n",
    "    return population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681885"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/alberto/LPSim/traffic_phase_transition/data/carto/BOS/potential/FitFluxesParameters.json','r')as f:\n",
    "    fitGLM = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155611/2545448775.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  VectorField['Ti'][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VectorField['Ti'][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET Vec Field & Pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ComputeInitPotential = True\n",
    "ComputeInitVF = True\n",
    "if ComputeInitVF:\n",
    "    VectorField = GetVectorField(Tij,df_distance)\n",
    "    VectorFieldDir = os.path.join(TRAFFIC_DIR,'data','carto',name,'grid',str(grid_size))\n",
    "    SaveVectorField(VectorField,VectorFieldDir)\n",
    "\n",
    "if ComputeInitPotential:\n",
    "    lattice = GetPotentialLattice(lattice,VectorField)\n",
    "    lattice = SmoothPotential(lattice)\n",
    "    PotentialDataframe = ConvertLattice2PotentialDataframe(lattice)\n",
    "    PotentialDataframe = CompletePotentialDataFrame(VectorField,grid,PotentialDataframe)\n",
    "    SavePotentialDataframe(PotentialDataframe,dir_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIFY  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Modify Population -> Compute Fluxes -> Get Vector Field -> Compute Modified Potential -> Compute Lorenz -> Compute OD\n",
    "\n",
    "with open('/home/alberto/LPSim/traffic_phase_transition/data/carto/BOS/potential/FitFluxesParameters.json','r')as f:\n",
    "    fitGLM = json.load(f)\n",
    "p0 = fraction\n",
    "\n",
    "Population = ModifyPop(Population)\n",
    "Tij_modified = ComputeFluxesModifiedPopulation(Population) \n",
    "VectorField = ComputeVectorFieldModified(Tij,df_distance)\n",
    "Potential = ComputePotentialModified(VectorField)\n",
    "\n",
    "p = ComputeLorenzCurve(Potential)\n",
    "OD_DemandFromFluxes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIFIED OD CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/alberto/LPSim/traffic_phase_transition/data/carto/BOS/grid/0.02/origindest2grid.json','r') as f:\n",
    "    OD2grid = json.load(f)\n",
    "\n",
    "with open('/home/alberto/LPSim/traffic_phase_transition/data/carto/BOS/grid/0.02/grid2origindest.json','r') as f:\n",
    "    grid2OD = json.load(f)\n",
    "with open('/home/alberto/LPSim/traffic_phase_transition/data/carto/BOS/osmid2idx.json') as f:\n",
    "    osmid2index = json.load(f)\n",
    "\n",
    "def CumulativeODFromGrid(O_vector,D_vector,OD_vector,osmid2index,grid2OD,start,multiplicative_factor,seconds_in_minute):\n",
    "    total_number_people_considered = 0\n",
    "    total_number_people_not_considered = 0\n",
    "    count_line = 0\n",
    "    users_id = []\n",
    "    time_ = []\n",
    "    origins = []\n",
    "    destinations = []\n",
    "    osmid_origin = []\n",
    "    osmid_destination = []\n",
    "    print('number of couples of origin-destination: ',len(O_vector))\n",
    "    for i in range(len(O_vector)):\n",
    "        origin = O_vector[i]\n",
    "        destination = D_vector[i]\n",
    "        number_people = OD_vector[i]\n",
    "        bin_width = 1                        \n",
    "        if number_people > 0:\n",
    "            iterations = multiplicative_factor*number_people/bin_width   \n",
    "            time_increment = 1/iterations\n",
    "            for it in range(int(iterations)):\n",
    "                try:\n",
    "                    Originbigger0 = len(grid2OD[origin])>0\n",
    "                except KeyError:\n",
    "                    total_number_people_not_considered += number_people\n",
    "                    break\n",
    "                try:\n",
    "                    Destinationbigger0 = len(grid2OD[destination])>0\n",
    "                except KeyError:\n",
    "                    total_number_people_not_considered += number_people\n",
    "                    break\n",
    "                if  Originbigger0 and Destinationbigger0:\n",
    "                    users_id.append(count_line)\n",
    "                    t = start*(seconds_in_minute**2) + it*time_increment*seconds_in_minute**2\n",
    "                    time_.append(t) # TIME IN HOURS\n",
    "                    i = np.random.randint(0,len(grid2OD[origin]))\n",
    "                    try:\n",
    "                        origins.append(osmid2index[grid2OD[origin][i]])\n",
    "                    except KeyError:\n",
    "                        total_number_people_not_considered += number_people\n",
    "                        raise KeyError('KeyError Polygon 2 OD: origin {0} i {1}'.format(origin,i))\n",
    "                    j = np.random.randint(0,len(grid2OD[destination]))                        \n",
    "                    try:\n",
    "                        destinations.append(osmid2index[grid2OD[destination][j]])\n",
    "                    except KeyError:\n",
    "                        total_number_people_not_considered += number_people\n",
    "                        raise KeyError('KeyError Polygon 2 OD: destination {0} j {1}'.format(origin,i))\n",
    "                    osmid_origin.append(grid2OD[origin][i])\n",
    "                    osmid_destination.append(grid2OD[destination][j])\n",
    "                    ## FILLING ORIGIN DESTINATION GRID ACCORDING TO THE ORIGIN DESTINATION NODES\n",
    "                    count_line += 1\n",
    "                    total_number_people_considered += 1\n",
    "    print('total_number_people_considered: ',total_number_people_considered)\n",
    "    print('total_number_people_not_considered: ',total_number_people_not_considered)\n",
    "    print('ratio: ',total_number_people_considered/(total_number_people_considered+total_number_people_not_considered))\n",
    "    return users_id,time_,origins,destinations,osmid_origin,osmid_destination\n",
    "\n",
    "def OD_from_T_Modified(Tij_modified,\n",
    "                       CityName2RminRmax,\n",
    "                       NameCity,\n",
    "                       osmid2index,\n",
    "                       grid2OD,\n",
    "                       p,\n",
    "                       save_dir_local,\n",
    "                       start = 7,\n",
    "                       end = 8\n",
    "                       ):\n",
    "    ROutput = []\n",
    "    # NOTE: ADD HERE THE POSSIBILITY OF HAVING OD FROM POTENTIAL CONSIDERATIONS\n",
    "    O_vector = Tij_modified['origin']\n",
    "    D_vector = Tij_modified['destination']\n",
    "    OD_vector = Tij_modified['number_people']\n",
    "    # START TAB\n",
    "    R = np.sum(OD_vector)/3600 # R is the number of people that move in one second (that is the time interval for the evolution )\n",
    "    Rmin = CityName2RminRmax[NameCity][0]\n",
    "    Rmax = CityName2RminRmax[NameCity][1]\n",
    "    spacing = (Rmax/R - Rmin/R)/20\n",
    "    for multiplicative_factor in np.arange(Rmin/R,Rmax/R,spacing):\n",
    "        R = np.sum(OD_vector)/3600 \n",
    "        if os.path.isfile(os.path.join(save_dir_local,'OD','{0}_oddemand_{1}_{2}_R_{3}.csv'.format(NameCity,start,end,int(multiplicative_factor*R)))):\n",
    "            cprint(os.path.join(save_dir_local,'OD','{0}_oddemand_{1}_{2}_R_{3}.csv'.format(NameCity,start,end,int(multiplicative_factor*R))),'cyan')\n",
    "            ROutput.append(int(multiplicative_factor*R))\n",
    "            continue\n",
    "        else:\n",
    "            cprint('COMPUTING {}'.format(os.path.join(save_dir_local,'OD','{0}_oddemand_{1}_{2}_R_{3}.csv'.format(NameCity,start,end,int(multiplicative_factor*R)))),'cyan')\n",
    "            users_id,time_,origins,destinations,osmid_origin,osmid_destination = CumulativeODFromGrid(O_vector,D_vector,OD_vector,osmid2index,grid2OD,start,multiplicative_factor,60)\n",
    "            df1 = pd.DataFrame({\n",
    "                'SAMPN':users_id,\n",
    "                'PERNO':users_id,\n",
    "                'origin_osmid':osmid_origin,\n",
    "                'destination_osmid':osmid_destination,\n",
    "                'dep_time':time_,\n",
    "                'origin':origins,\n",
    "                'destination':destinations,\n",
    "                })\n",
    "            print('df1:\\n',df1.head())\n",
    "            R = multiplicative_factor*R\n",
    "            ROutput.append(int(R))\n",
    "            df1.to_csv('')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
