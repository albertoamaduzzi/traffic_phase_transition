{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from shapely.geometry import box,LineString,Point,MultiPoint,MultiLineString,MultiPolygon,Polygon\n",
    "from shapely.ops import unary_union\n",
    "import socket\n",
    "from collections import defaultdict\n",
    "from numba import prange\n",
    "import gc\n",
    "current_dir = os.path.join(os.getcwd()) \n",
    "mother_path = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "print('mother_path:', mother_path)\n",
    "sys.path.append(os.path.join(mother_path, 'PreProcessing'))\n",
    "sys.path.append(os.path.join(mother_path))\n",
    "from FittingProcedures import *\n",
    "from plot import *\n",
    "from Potential import *\n",
    "from Grid import *\n",
    "from PreprocessingObj import *\n",
    "from ODfromfma import *\n",
    "import time\n",
    "from GeometrySphere import *\n",
    "from Polycentrism import *\n",
    "from PolycentrismPlot import *\n",
    "from ModifyPotential import *\n",
    "from MainPolycentrism import *\n",
    "\n",
    "#import rustworkx as rw\n",
    "import ast\n",
    "## BASIC PARAMS\n",
    "gc.set_threshold(10000,50,50)\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "})\n",
    "\n",
    "if socket.gethostname()=='artemis.ist.berkeley.edu':\n",
    "    TRAFFIC_DIR = '/home/alberto/LPSim/traffic_phase_transition'\n",
    "else:\n",
    "    TRAFFIC_DIR = os.getenv('TRAFFIC_DIR')\n",
    "name = 'BOS'\n",
    "grid_size = 0.02\n",
    "hexagon_resolution = 8\n",
    "dir_grid = os.path.join(TRAFFIC_DIR,'data','carto',name,'grid',str(grid_size))\n",
    "\n",
    "## BASIC NEEDED OBJECTS\n",
    "SFO_obj = GeometricalSettingsSpatialPartition(name,TRAFFIC_DIR)\n",
    "bbox = SFO_obj.bounding_box\n",
    "minx, miny, maxx, maxy = bbox\n",
    "dir_geometries = os.path.join(TRAFFIC_DIR,'data','carto','{0}'.format(name))\n",
    "grid = GetGrid(grid_size,SFO_obj.bounding_box,'EPSG:4326',dir_geometries)\n",
    "grid = GetBoundariesInterior(grid,SFO_obj)\n",
    "df_distance,FoundDistMat = GetDirectionMatrix(dir_geometries,grid_size)\n",
    "Tij = GetODGrid(dir_geometries,str(grid_size))\n",
    "lattice = nx.read_graphml(os.path.join(dir_grid,\"centroid_lattice.graphml\"))\n",
    "#VectorField = pd.read_csv('/home/alberto/LPSim/traffic_phase_transition/data/carto/BOS/grid/0.02/VectorField.csv')\n",
    "#Potential = pd.read_csv('/home/alberto/LPSim/traffic_phase_transition/data/carto/BOS/grid/0.02/PotentialDataFrame.csv')\n",
    "\n",
    "# GET POTENTIAL AND VECTOR FIELD\n",
    "VectorField = GetVectorField(Tij,df_distance)\n",
    "VectorFieldDir = os.path.join(TRAFFIC_DIR,'data','carto',name,'grid',str(grid_size))\n",
    "lattice = GetPotentialLattice(lattice,VectorField)\n",
    "lattice = SmoothPotential(lattice)\n",
    "PotentialDataframe = ConvertLattice2PotentialDataframe(lattice)\n",
    "PotentialDataframe = CompletePotentialDataFrame(VectorField,grid,PotentialDataframe)\n",
    "SumPot = np.sum(PotentialDataframe['V_out']) \n",
    "NumGridEdge = grid[grid['relation_to_line']=='edge'].shape[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTE PI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FIND VMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Look for maximal configuration of POT D POT. I do not trust the Pereira approach to the problem.\n",
    "Input:\n",
    "    Indices of the grid that are inside the polygon\n",
    "Description:\n",
    "    Looking for max starting from an homogeneous configuration of the potential fixed the distances among different parts of the grid\n",
    "'''\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize,anneal\n",
    "from deap import base, creator, tools, algorithms\n",
    "from pyswarm import pso\n",
    "\n",
    "# Objective function\n",
    "def objective_function(ViVj,Filtered_Distance):\n",
    "    return np.sum(ViVj * Filtered_Distance)\n",
    "\n",
    "# Constraint function: sum of rows and columns should be constant\n",
    "def constraint_function(V,SumPot):\n",
    "    return np.sum(V, axis=0) - constant_sum_rows\n",
    "\n",
    "def MinimizationSquares(initial_V,d_ij,SumPot,verbose = True):\n",
    "    '''\n",
    "        Trying to minimize the V function for the PI. \n",
    "        I do not trust the ansatz Pereira uses to define the most polycentric city.\n",
    "    '''\n",
    "    # Bounds for V (optional, but can help guide the optimization)\n",
    "    bounds = [(0, SumPot)] * len(initial_V)  # V_i should be non-negative\n",
    "    # Constraints for V (equality constraints for sum of rows and columns)\n",
    "    constraints = ({'type': 'eq', 'fun': constraint_function})\n",
    "    # Optimization\n",
    "    result = minimize(objective_function, initial_V.flatten(), args=(d_ij.flatten()), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    # Reshape the optimized V matrix\n",
    "    optimal_V = result.x.reshape(3, 3)\n",
    "    if verbose:\n",
    "        print(\"Optimal V:\")\n",
    "        print(optimal_V)\n",
    "        print(\"Objective function value:\", result.fun)\n",
    "\n",
    "def MinimizationAnnealing(initial_V,d_ij,verbose = True):\n",
    "    result = anneal(objective_function, initial_V.flatten(), args=(d_ij.flatten()), constraint=constraint_function)\n",
    "\n",
    "    # Reshape the optimized V matrix\n",
    "    optimal_V = result.reshape(3, 3)\n",
    "    if verbose:\n",
    "        print(\"Optimal V:\")\n",
    "        print(optimal_V)\n",
    "        print(\"Objective function value:\", objective_function(optimal_V.flatten(), d_ij.flatten()))    \n",
    "\n",
    "\n",
    "def MinimizationByGeneticAlgo(verbose = True):\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", np.ndarray, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_float\", np.random.uniform, 0, 10)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=9)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register(\"evaluate\", objective_function, d=d_ij.flatten())\n",
    "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    # Optimization\n",
    "    population = toolbox.population(n=50)\n",
    "    algorithms.eaMuPlusLambda(population, toolbox, mu=50, lambda_=100, cxpb=0.5, mutpb=0.2, ngen=100)\n",
    "\n",
    "    # Get the best individual\n",
    "    best_individual = tools.selBest(population, k=1)[0]\n",
    "\n",
    "    # Reshape the optimized V matrix\n",
    "    optimal_V = np.array(best_individual).reshape(3, 3)\n",
    "    if verbose:\n",
    "        print(\"Optimal V:\")\n",
    "        print(optimal_V)\n",
    "        print(\"Objective function value:\", objective_function(best_individual, d_ij.flatten())[0])    \n",
    "# Tira dadi per Arrotondare a intero i flussi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMPUTE POLYCENTRISM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE NEW CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/aamad/Desktop/phd/berkeley/traffic_phase_transition/data/carto/BOS/grid/0.02/origindest2grid.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/aamad/Desktop/phd/berkeley/traffic_phase_transition/data/carto/BOS/grid/0.02/origindest2grid.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     OD2grid \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/aamad/Desktop/phd/berkeley/traffic_phase_transition/data/carto/BOS/grid/0.02/grid2origindest.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/anaconda3/envs/geostuff/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/aamad/Desktop/phd/berkeley/traffic_phase_transition/data/carto/BOS/grid/0.02/origindest2grid.json'"
     ]
    }
   ],
   "source": [
    "with open('/home/aamad/Desktop/phd/berkeley/traffic_phase_transition/data/carto/BOS/grid/0.02/origindest2grid.json','r') as f:\n",
    "    OD2grid = json.load(f)\n",
    "\n",
    "with open('/home/aamad/Desktop/phd/berkeley/traffic_phase_transition/data/carto/BOS/grid/0.02/grid2origindest.json','r') as f:\n",
    "    grid2OD = json.load(f)\n",
    "with open('/home/aamad/Desktop/phd/berkeley/traffic_phase_transition/data/carto/BOS/osmid2idx.json') as f:\n",
    "    osmid2index = json.load(f)\n",
    "\n",
    "list_peaks = [2,3,4,5,6,8,10,100]\n",
    "InfoConfigurationPolicentricity = {num_peaks: defaultdict() for num_peaks in list_peaks}\n",
    "Covarinaces = [1,2,4,8,10,15,20,30,50,100]\n",
    "for cv in Covarinaces:\n",
    "    for distribution in ['gaussian','exponential']:\n",
    "        InfoCenters = {'center_settings': {\"type\":distribution},'covariance_settings':{\"covariances\":{\"cvx\":cv,\"cvy\":cv},\"Isotropic\": True,\"Random\": False}}\n",
    "        #parameter_values = ((InfoConfigurationPolicentricity,grid,SFO_obj,Tij,df_distance,num_peaks) for num_peaks in list_peaks)\n",
    "        for num_peaks in list_peaks:\n",
    "            ModifyMorphologyCity(InfoConfigurationPolicentricity,grid,SFO_obj,Tij,df_distance,lattice,num_peaks,TRAFFIC_DIR,name,grid_size,InfoCenters,fraction_fluxes = 200,verbose = True)\n",
    "#    OD_from_T_Modified(InfoConfigurationPolicentricity[pv[-1]]['Tij'],CityName2RminRmax,'BOS',osmid2index,grid2OD,1,'/home/aamad/Desktop/phd/traffic_phase_transition/data/carto/BOS/OD',start = 7,end = 8)\n",
    "#with multiprocessing.Pool(processes=multiprocessing.cpu_count() - 4) as pool:\n",
    "    # Map the function to the parameter values\n",
    "#    pool.map(ModifyMorphologyCity, parameter_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATION OD FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "{'logk': 0.0003055803472447064, 'alpha': 0.0002546775749831938, 'gamma': -0.07627729954795813, '1/d0': 4.8774299414384545}\n",
    "Number centers considered:  2\n",
    "[ 3.37484752 51.76501691]\n",
    "bin index:  2\n",
    "Length filtered grid:  32  rv:  3.3748475174250743\n",
    "bin index:  23\n",
    "Length filtered grid:  60  rv:  51.76501690675754\n",
    "New population:  574776957.9199114\n",
    "k:  1.0003056270416752  alpha:  0.0002546775749831938  beta:  -0.07627729954795813  d0:  4.8774299414384545\n",
    "<k*p>:  165358.83\n",
    "<p**alpha>:  1.0017573\n",
    "<p**beta>:  0.6491281\n",
    "<exp(-d/d0)>:  0.010571069\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "with open('/home/aamad/Desktop/phd/berkeley/traffic_phase_transition/data/carto/BOS/potential/FitVespignani.json','r')as f:\n",
    "    fitGLM = json.load(f)\n",
    "print(fitGLM)\n",
    "k = np.exp(fitGLM['logk'])\n",
    "alpha =fitGLM['alpha']\n",
    "beta = fitGLM['gamma']\n",
    "d0 = fitGLM['1/d0']\n",
    "list_peaks = [2,3,4,5,6,8,10]\n",
    "InfoConfigurationPolicentricity = {num_peaks: defaultdict() for num_peaks in list_peaks}\n",
    "total_population = np.sum(grid['population'])\n",
    "total_flux = np.sum(Tij['number_people'])\n",
    "\n",
    "population,centroidx,centroidy,index,filtered_grid = FilterPopulation(grid)\n",
    "coords_center,_ = ExtractCenterByPopulation(grid)\n",
    "\n",
    "#CenterMass = ComputeCM(grid,coords_center)\n",
    "\n",
    "grid['is_populated'] = grid['population']>0\n",
    "grid['coords'] = grid.apply(lambda x: ProjCoordsTangentSpace(x['centroidx'],x['centroidy'],coords_center[0],coords_center[1]),axis = 1)\n",
    "grid['distance_from_center'] = grid.apply(lambda x: polar_coordinates(np.array([x['centroidx'],x['centroidy']]),np.array(x['coords']))[0],axis = 1)\n",
    "PrintInfoFluxPop(grid,Tij)\n",
    "for num_peaks in list_peaks:\n",
    "    InfoConfigurationPolicentricity[num_peaks]['grid'] = grid.copy()\n",
    "    InfoConfigurationPolicentricity[num_peaks]['Tij'] = Tij.copy()\n",
    "for num_peaks in list_peaks:\n",
    "    print('Number centers considered: ',num_peaks)\n",
    "    index_centers = GenerateIndexCenters(grid,num_peaks)\n",
    "    PlotPositionCenters(grid,SFO_obj,index_centers)\n",
    "    covariances = SetCovariances(index_centers)\n",
    "    new_population = ComputeNewPopulation(grid,index_centers,covariances,total_population)\n",
    "    # Store Data About Population and Fluxes\n",
    "    \n",
    "    Factor = np.sum(grid['population'])/np.sum(new_population)\n",
    "    new_population = new_population*Factor\n",
    "    InfoConfigurationPolicentricity[num_peaks]['grid']['population'] = new_population\n",
    "    InfoConfigurationPolicentricity[num_peaks]['grid'].plot(column = 'population')\n",
    "    plt.show()\n",
    "#    IPF = ipfn.ipfn(np.array([new_population]), np.array([[int(total_population)]]), np.array([[0]]),convergence_rate=0.01, max_iteration=1000, verbose=True)\n",
    "#    new_population_ipfn = IPF.iteration()\n",
    "#    InfoConfigurationPolicentricity[num_peaks]['grid']['new_population'] = new_population_ipfn[0][0]\n",
    "    t0 = time.time() \n",
    "    Modified_Fluxes =  GravitationalModel(InfoConfigurationPolicentricity[num_peaks]['grid']['population'].to_numpy(dtype = np.float32),df_distance['distance'].to_numpy(dtype = np.float32),k,alpha,beta,d0)\n",
    "    Multiplicator = total_flux/Modified_Fluxes.sum()\n",
    "    Modified_Fluxes = Modified_Fluxes*Multiplicator\n",
    "    t1 = time.time()\n",
    "    print('Time to compute the model: ',t1 - t0)\n",
    "    t0 = time.time()\n",
    "#    IPF = ipfn.ipfn(np.array([Modified_Fluxes]), np.array([[total_flux]]), np.array([[0]]),convergence_rate=0.01, max_iteration=1000, verbose=True)\n",
    "#    Modified_Fluxes_ipfn = IPF.iteration()\n",
    "    InfoConfigurationPolicentricity[num_peaks]['Tij']['number_people'] = Modified_Fluxes    #Modified_Fluxes_ipfn[0][0]    \n",
    "    print('Afeter Population Generation and Gravity:')\n",
    "    PrintInfoFluxPop(InfoConfigurationPolicentricity[num_peaks]['grid'],InfoConfigurationPolicentricity[num_peaks]['Tij'])\n",
    "    print(\"----------------------------------\")\n",
    "    n,bins = np.histogram(InfoConfigurationPolicentricity[num_peaks]['Tij']['number_people'].loc[InfoConfigurationPolicentricity[num_peaks]['Tij']['number_people']>0],bins = 100)\n",
    "    n1,bins1 = np.histogram(Tij['number_people'].loc[Tij['number_people']>0],bins = 100)\n",
    "    plt.scatter(bins[:-1],n)\n",
    "    plt.scatter(bins1[:-1],n1)\n",
    "    plt.yscale('log')\n",
    "    plt.legend(['Fitted','Original'])\n",
    "    plt.title('DIstribution fluxes fitted')\n",
    "    plt.show()\n",
    "    plt.hist(InfoConfigurationPolicentricity[num_peaks]['Tij']['number_people'],bins = 20)\n",
    "    plt.title('DIstribution fluxes fitted')\n",
    "    plt.show()\n",
    "    t1 = time.time()\n",
    "    print('Time to compute the ipfn: ',t1 - t0)    \n",
    "    t0 = time.time()\n",
    "    InfoConfigurationPolicentricity[num_peaks]['vector_field'] = GetVectorField(InfoConfigurationPolicentricity[num_peaks]['Tij'],df_distance)\n",
    "    t1 = time.time()\n",
    "    print('Time to compute the vector field: ',t1 - t0)\n",
    "    lattice = GetPotentialLattice(lattice,InfoConfigurationPolicentricity[num_peaks]['vector_field'])\n",
    "    lattice = SmoothPotential(lattice)\n",
    "    InfoConfigurationPolicentricity[num_peaks]['potential'] = ConvertLattice2PotentialDataframe(lattice)\n",
    "    InfoConfigurationPolicentricity[num_peaks]['potential'] = CompletePotentialDataFrame(VectorField,InfoConfigurationPolicentricity[num_peaks]['grid'],InfoConfigurationPolicentricity[num_peaks]['potential'])\n",
    "    print('*********** COMPUTE UCI ************')\n",
    "    SumPot = InfoConfigurationPolicentricity[num_peaks]['potential']['V_out'].sum()\n",
    "    NumGridEdge = grid[grid['relation_to_line']=='edge'].shape[0]\n",
    "    PI = LaunchComputationPI(df_distance,InfoConfigurationPolicentricity[num_peaks]['grid'],SumPot,NumGridEdge,InfoConfigurationPolicentricity[num_peaks]['potential'])\n",
    "    result_indices,angle,cumulative,Fstar = LorenzCenters(InfoConfigurationPolicentricity[num_peaks]['potential']['V_out'].to_numpy())\n",
    "    InfoConfigurationPolicentricity[num_peaks]['PI'] = PI\n",
    "    LC = Fstar/len(cumulative)\n",
    "    InfoConfigurationPolicentricity[num_peaks]['LC'] = LC\n",
    "    UCI = PI*LC\n",
    "    InfoConfigurationPolicentricity[num_peaks]['UCI'] = UCI\n",
    "    print('Sum Potential: ',SumPot)\n",
    "    print('Number of Edges boundary: ',NumGridEdge)\n",
    "    print('LC: ',LC,'PI: ',PI,'UCI: ',UCI)\n",
    "    print('************PLOTTING************')\n",
    "    dir_grid = os.path.join(TRAFFIC_DIR,'data','carto',name,'OD')\n",
    "    if not os.path.exists(dir_grid):\n",
    "        os.mkdir(dir_grid)\n",
    "    dir_grid = os.path.join(dir_grid,str(grid_size))\n",
    "    if not os.path.exists(dir_grid):\n",
    "        os.mkdir(dir_grid)\n",
    "    dir_grid = os.path.join(dir_grid,str(num_peaks))\n",
    "    if not os.path.exists(dir_grid):\n",
    "        os.mkdir(dir_grid)\n",
    "    dir_grid = os.path.join(dir_grid,'UCI_{}'.format(round(UCI,3)))\n",
    "    if not os.path.exists(dir_grid):\n",
    "        os.mkdir(dir_grid)\n",
    "    PlotVFPotMass(InfoConfigurationPolicentricity[num_peaks]['grid'],SFO_obj,InfoConfigurationPolicentricity[num_peaks]['potential'],InfoConfigurationPolicentricity[num_peaks]['vector_field'],dir_grid,label_potential = 'population',label_fluxes = 'Ti')\n",
    "    PotentialContour(InfoConfigurationPolicentricity[num_peaks]['grid'],InfoConfigurationPolicentricity[num_peaks]['potential'],SFO_obj,dir_grid)\n",
    "    PotentialSurface(InfoConfigurationPolicentricity[num_peaks]['grid'],SFO_obj,InfoConfigurationPolicentricity[num_peaks]['potential'],dir_grid)\n",
    "    PlotRotorDistribution(InfoConfigurationPolicentricity[num_peaks]['grid'],InfoConfigurationPolicentricity[num_peaks]['potential'],dir_grid)\n",
    "    fig,ax = plt.subplots(1,1,figsize = (10,10))\n",
    "    PlotLorenzCurve(ax,cumulative,Fstar,result_indices,shift = 0.1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotVFPotMass(InfoConfigurationPolicentricity[num_peaks]['grid'],SFO_obj,InfoConfigurationPolicentricity[num_peaks]['potential'],InfoConfigurationPolicentricity[num_peaks]['vector_field'],dir_grid,label_potential = 'population',label_fluxes = 'Ti')\n",
    "PotentialContour(InfoConfigurationPolicentricity[num_peaks]['grid'],InfoConfigurationPolicentricity[num_peaks]['potential'],SFO_obj,dir_grid)\n",
    "PotentialSurface(InfoConfigurationPolicentricity[num_peaks]['grid'],SFO_obj,InfoConfigurationPolicentricity[num_peaks]['potential'],dir_grid)\n",
    "PlotRotorDistribution(InfoConfigurationPolicentricity[num_peaks]['grid'],InfoConfigurationPolicentricity[num_peaks]['potential'],dir_grid)\n",
    "fig,ax = plt.subplots(1,1,figsize = (10,10))\n",
    "PlotLorenzCurve(ax,cumulative,Fstar,result_indices,shift = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
