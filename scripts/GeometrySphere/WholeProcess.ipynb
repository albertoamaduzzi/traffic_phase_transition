{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE GEOMETRY and FLUXES FROM DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mother_path: /home/alberto/LPSim/traffic_phase_transition/scripts\n",
      "PyMC3 not installed\n"
     ]
    }
   ],
   "source": [
    "# A \n",
    "import ast\n",
    "# C\n",
    "from collections import defaultdict\n",
    "# G\n",
    "import gc\n",
    "import geopandas as gpd\n",
    "# J\n",
    "import json\n",
    "# M\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from multiprocessing import Pool\n",
    "# N\n",
    "from numba import prange\n",
    "import numpy as np\n",
    "# O\n",
    "import os\n",
    "# P\n",
    "import pandas as pd\n",
    "# S\n",
    "from shapely.geometry import box,LineString,Point,MultiPoint,MultiLineString,MultiPolygon,Polygon\n",
    "from shapely.ops import unary_union\n",
    "import socket\n",
    "import sys\n",
    "# T\n",
    "from termcolor import  cprint\n",
    "import time\n",
    "\n",
    "# Project specific\n",
    "# A\n",
    "from AlgorithmCheck import *\n",
    "# C\n",
    "from ComputeGrid import *\n",
    "from ComputeHexagon import *\n",
    "# F\n",
    "current_dir = os.path.join(os.getcwd()) \n",
    "mother_path = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "print('mother_path:', mother_path)\n",
    "sys.path.append(os.path.join(mother_path, 'PreProcessing'))\n",
    "sys.path.append(os.path.join(mother_path))\n",
    "from FittingProcedures import *\n",
    "# G\n",
    "from GeometrySphere import *\n",
    "from GenerateModifiedFluxesSimulation import *\n",
    "from GravitationalFluxes import *                                               # FIT section\n",
    "from Grid import *\n",
    "# H \n",
    "from Hexagon import *\n",
    "if socket.gethostname()=='artemis.ist.berkeley.edu':\n",
    "    sys.path.append(os.path.join('/home/alberto/LPSim','traffic_phase_transition','scripts','ServerCommunication'))\n",
    "else:\n",
    "    sys.path.append(os.path.join(os.getenv('TRAFFIC_DIR'),'scripts','ServerCommunication'))\n",
    "from HostConnection import *\n",
    "# M\n",
    "from MainPolycentrism import *\n",
    "from ModifyPotential import *\n",
    "# O \n",
    "from ODfromfma import *\n",
    "# P\n",
    "from plot import *\n",
    "from Polycentrism import *\n",
    "from PolycentrismPlot import *\n",
    "from PolygonSettings import *\n",
    "from Potential import *\n",
    "from PreprocessingObj import *\n",
    "\n",
    "\n",
    "\n",
    "## BASIC PARAMS\n",
    "gc.set_threshold(10000,50,50)\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": False,\n",
    "})\n",
    "StateAlgorithm = InitWholeProcessStateFunctions()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single City Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always Needed\n",
    "NameCity = \"BOS\"\n",
    "NameCities = [\"BOS\"]\n",
    "\n",
    "grid_size = 0.02\n",
    "hexagon_resolution = 8\n",
    "# Computation Grid\n",
    "ArgsComputationGrid = [(NameCity,TRAFFIC_DIR,[grid_size])]\n",
    "ArgsComputationHexagon = [(NameCity,TRAFFIC_DIR,[hexagon_resolution])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Cities Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always Needed\n",
    "NameCities = os.listdir(os.path.join(TRAFFIC_DIR,'data','carto'))\n",
    "if len(NameCities)==0:\n",
    "    cprint('No city found in the data/cart folder', 'red')\n",
    "    sys.exit()\n",
    "# Computation Grid\n",
    "ArgsComputationGrid = [(NameCities[i],TRAFFIC_DIR,[grid_size]) for i in range(len(list_cities))]\n",
    "ArgsComputationHexagon = [(NameCities[i],TRAFFIC_DIR,[hexagon_resolution]) for i in range(len(list_cities))]\n",
    "grid_size = 0.02\n",
    "hexagon_resolution = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Grid after Hexagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arg in ArgsComputationHexagon:\n",
    "    ComputeHexagon(*arg)\n",
    "for arg in ArgsComputationGrid:\n",
    "    GeometricalInfo = GeometricalSettingsSpatialPartition(NameCity,TRAFFIC_DIR)\n",
    "    ComputeGrid(GeometricalInfo,*arg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTE VECTOR FIELD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description: Upload grid that must be already computed,\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for NameCity in NameCities: \n",
    "    dir_grid = os.path.join(TRAFFIC_DIR,'data','carto',NameCity,'grid',str(grid_size))\n",
    "    ## BASIC NEEDED OBJECTS\n",
    "    if not StateAlgorithm[\"GeometricalSettingsSpatialPartition\"]:\n",
    "        SFO_obj = GeometricalSettingsSpatialPartition(NameCity,TRAFFIC_DIR)\n",
    "        bbox = SFO_obj.bounding_box\n",
    "        minx, miny, maxx, maxy = bbox\n",
    "    else:\n",
    "        pass\n",
    "    DirGeometry = os.path.join(TRAFFIC_DIR,'data','carto','{0}'.format(NameCity))\n",
    "    if not StateAlgorithm[\"GetGrid\"]:\n",
    "        grid = GetGrid(grid_size,SFO_obj.bounding_box,'EPSG:4326',DirGeometry)\n",
    "        StateAlgorithm[\"GetGrid\"] = True\n",
    "    else:\n",
    "        pass\n",
    "    if not StateAlgorithm[\"GetBoundariesInterior\"]:\n",
    "        grid = GetBoundariesInterior(grid,SFO_obj)\n",
    "        StateAlgorithm[\"GetBoundariesInterior\"] = True\n",
    "    else:\n",
    "        pass\n",
    "    if not StateAlgorithm[\"GetDirectionMatrix\"]:\n",
    "        df_distance,FoundDistMat = GetDirectionMatrix(DirGeometry,grid_size)\n",
    "        StateAlgorithm[\"GetDirectionMatrix\"] = True\n",
    "    else:\n",
    "        pass\n",
    "    if not StateAlgorithm[\"GetODGrid\"]:\n",
    "        Tij = GetODGrid(DirGeometry,str(grid_size))\n",
    "        StateAlgorithm[\"GetODGrid\"] = True\n",
    "    else:\n",
    "        pass\n",
    "    if not StateAlgorithm[\"GetLattice\"]:\n",
    "        lattice = nx.read_graphml(os.path.join(dir_grid,\"centroid_lattice.graphml\"))\n",
    "        StateAlgorithm[\"GetLattice\"] = True\n",
    "    else:\n",
    "        pass\n",
    "    if not StateAlgorithm[\"GetVectorField\"]:\n",
    "        VectorField = GetVectorField(Tij,df_distance)\n",
    "        StateAlgorithm[\"GetVectorField\"] = True\n",
    "    VectorFieldDir = os.path.join(TRAFFIC_DIR,'data','carto',NameCity,'grid',str(grid_size))\n",
    "    if not StateAlgorithm[\"GetPotentialLattice\"]:\n",
    "        lattice = GetPotentialLattice(lattice,VectorField)\n",
    "        StateAlgorithm[\"GetPotentialLattice\"] = True\n",
    "    else:\n",
    "        pass\n",
    "    if not StateAlgorithm[\"GetPotentialDataframe\"]:\n",
    "        lattice = SmoothPotential(lattice)\n",
    "        StateAlgorithm[\"GetPotentialDataframe\"] = True\n",
    "    else:\n",
    "        pass\n",
    "    if not StateAlgorithm[\"ConvertLattice2PotentialDataframe\"]:\n",
    "        PotentialDataframe = ConvertLattice2PotentialDataframe(lattice)\n",
    "        StateAlgorithm[\"ConvertLattice2PotentialDataframe\"] = True\n",
    "    else:\n",
    "        pass\n",
    "    if not StateAlgorithm[\"CompletePotentialDataFrame\"]:\n",
    "        PotentialDataframe = CompletePotentialDataFrame(VectorField,grid,PotentialDataframe)\n",
    "        StateAlgorithm[\"CompletePotentialDataFrame\"] = True\n",
    "    else:\n",
    "        pass\n",
    "    if os.path.isfile(os.path.join(dir_grid,'PotentialDataframe.csv')):\n",
    "        SavePotentialDataframe(PotentialDataframe,dir_grid)\n",
    "    if os.path.isfile(os.path.join(VectorFieldDir,'VectorField.csv')):\n",
    "        SaveVectorField(VectorField,VectorFieldDir)\n",
    "    SumPot = np.sum(PotentialDataframe['V_out']) \n",
    "    NumGridEdge = grid[grid['relation_to_line']=='edge'].shape[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT GRAVITATIONAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Compute The Fit From Data.\n",
    "\"\"\"\n",
    "if not StateAlgorithm[\"GeometricalSettingsSpatialPartition\"]:\n",
    "    SFO_obj = GeometricalSettingsSpatialPartition(NameCity,TRAFFIC_DIR)\n",
    "    bbox = SFO_obj.bounding_box\n",
    "    minx, miny, maxx, maxy = bbox\n",
    "    DirGeometry = os.path.join(TRAFFIC_DIR,'data','carto','{0}'.format(NameCity))\n",
    "if not StateAlgorithm[\"GetGrid\"]:\n",
    "    grid = GetGrid(grid_size,SFO_obj.bounding_box,'EPSG:4326',DirGeometry)\n",
    "    StateAlgorithm[\"GetGrid\"] = True\n",
    "else:\n",
    "    pass\n",
    "if not StateAlgorithm[\"GetBoundariesInterior\"]:\n",
    "    grid = GetBoundariesInterior(grid,SFO_obj)\n",
    "    StateAlgorithm[\"GetBoundariesInterior\"] = True\n",
    "else:\n",
    "    pass\n",
    "if not StateAlgorithm[\"GetDirectionMatrix\"]:\n",
    "    df_distance,FoundDistMat = GetDirectionMatrix(DirGeometry,grid_size)\n",
    "    StateAlgorithm[\"GetDirectionMatrix\"] = True\n",
    "else:\n",
    "    pass\n",
    "if not StateAlgorithm[\"GetODGrid\"]:\n",
    "    Tij = GetODGrid(DirGeometry,str(grid_size))\n",
    "    StateAlgorithm[\"GetODGrid\"] = True\n",
    "else:\n",
    "    pass\n",
    "\n",
    "for NameCity in NameCities:\n",
    "    potential_dir = os.path.join(TRAFFIC_DIR,'data','carto',NameCity,'grid',str(grid_size),\"potential\")\n",
    "    VespignaniBlock(df_distance,grid,Tij,potential_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIFY POTENTIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for NameCity in NameCities:\n",
    "    with open(os.path.join(TRAFFIC_DIR,'data','carto',NameCity,'grid','0.02','origindest2grid.json'),'r') as f:\n",
    "        OD2grid = json.load(f)\n",
    "    with open(os.path.join(TRAFFIC_DIR,'data','carto',NameCity,'grid','0.02','grid2origindest.json'),'r') as f:\n",
    "        grid2OD = json.load(f)\n",
    "    with open(os.path.join(TRAFFIC_DIR,'data','carto',NameCity,'osmid2idx.json'),'r') as f:\n",
    "        osmid2index = json.load(f)\n",
    "\n",
    "    list_peaks = [2,3,4,5,6,8,10,100,200,500] # [2,3,4,5,6,8,10,\n",
    "    InfoConfigurationPolicentricity = {num_peaks: defaultdict() for num_peaks in list_peaks}\n",
    "    Covarinaces = [1,2,4,8,10,15,20,30,50,100]\n",
    "    distributions = ['exponential']   \n",
    "    parallel = False\n",
    "    if not parallel:  \n",
    "        for cv in Covarinaces:\n",
    "            for distribution in distributions:#['gaussian','exponential']:#,'exponential']: # NOTE: There is some problem with the exponential distribution\n",
    "                InfoCenters = {'center_settings': {\"type\":distribution},'covariance_settings':{\"covariances\":{\"cvx\":cv,\"cvy\":cv},\"Isotropic\": True,\"Random\": False}}\n",
    "                #parameter_values = ((InfoConfigurationPolicentricity,grid,SFO_obj,Tij,df_distance,num_peaks) for num_peaks in list_peaks)\n",
    "                for num_peaks in list_peaks:\n",
    "                    InfoConfigurationPolicentricity,UCI = ModifyMorphologyCity(InfoConfigurationPolicentricity,grid,SFO_obj,Tij,df_distance,lattice,num_peaks,TRAFFIC_DIR,NameCity,grid_size,InfoCenters,fraction_fluxes = 200,verbose = True)\n",
    "                    if socket.gethostname()=='artemis.ist.berkeley.edu':\n",
    "                        SaveOd = \"/home/alberto/LPSim/LivingCity/berkeley_2018/new_full_network\"\n",
    "                    else:\n",
    "                        SaveOd = f'/home/aamad/Desktop/phd/traffic_phase_transition/data/carto/{NameCity}/OD'\n",
    "                    OD_from_T_Modified(InfoConfigurationPolicentricity[num_peaks]['Tij'],\n",
    "                                    CityName2RminRmax,\n",
    "                                    NameCity,\n",
    "                                    osmid2index,\n",
    "                                    grid2OD,\n",
    "                                    1,\n",
    "                                    SaveOd,\n",
    "                                    7,\n",
    "                                    8,\n",
    "                                    round(UCI,3))\n",
    "    else:\n",
    "        Args_OD_from_T_Modified = [(num_peaks, cv, distribution,InfoConfigurationPolicentricity,grid,SFO_obj,Tij,df_distance,lattice,TRAFFIC_DIR,NameCity,grid_size) for distribution in distributions for num_peaks in list_peaks for cv in Covarinaces]\n",
    "        with Pool(10) as p:\n",
    "            p.starmap(GenerateParallelODs, Args_OD_from_T_Modified)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "process ComputeNewFluxConfiguration{\n",
    "    input\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geostuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
